{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skdata.mnist.views import OfficialVectorClassification\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "from itertools import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Audio Data\n",
    "def generate_audio_wave(frequency=440.0, framerate=44100, amplitude=0.5):\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield float(amplitude) + math.cos(2.0*math.pi*float(frequency)*(float(i)/float(framerate)))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_seq(seq_leng):\n",
    "    \n",
    "    # Generate audio wave\n",
    "    wave = generate_audio_wave(amplitude=1)\n",
    "    \n",
    "    # Generate function values\n",
    "    data_seq = []\n",
    "    for i in range(seq_leng):\n",
    "        data_seq.append(wave.next())\n",
    "    return data_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_window(data, n_int, window_size):\n",
    "\n",
    "    input_data=[]\n",
    "    output_data=[]\n",
    "    \n",
    "    for i in range(0, n_int - window_size, 1):\n",
    "        seq_in = data[i:i + window_size]\n",
    "        seq_out = data[i + window_size]\n",
    "        input_data.append(seq_in)\n",
    "        output_data.append(seq_out)\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = generate_seq(100)\n",
    "\n",
    "# Input, Output\n",
    "input_data, output_data = generate_window(data, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(\"sin.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(input_data))):\n",
    "    features = input_data[i]\n",
    "    label = output_data[i]\n",
    "    # construct the Example proto boject\n",
    "    example = tf.train.Example(\n",
    "        # Example contains a Features proto object\n",
    "        features=tf.train.Features(\n",
    "          # Features contains a map of string to Feature proto objects\n",
    "          feature={\n",
    "            # A Feature contains one of either a float_list,\n",
    "            # float_list, or bytes_list\n",
    "            'label': tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=[label])),\n",
    "            'seq': tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=features)),\n",
    "    }))\n",
    "    \n",
    "    # use the proto object to serialize the example to a string\n",
    "    serialized = example.SerializeToString()\n",
    "    # write the serialized object to disk\n",
    "    writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 10 # MNIST data input (img shape: 28*28)\n",
    "num_hidden = 5 # hidden layer num of features\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"sin.tfrecords\"], num_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = tf.TFRecordReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, serialized_example = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([1], tf.float32),\n",
    "            'seq': tf.FixedLenFeature([10], tf.float32)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = features['label']\n",
    "seq = features['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print seq.get_shape()\n",
    "print label.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groups examples into batches randomly\n",
    "seq_batch, labels_batch = tf.train.shuffle_batch(\n",
    "    [seq, label], batch_size=num_hidden,\n",
    "    capacity=2000,\n",
    "    min_after_dequeue=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "print seq_batch.get_shape()\n",
    "print labels_batch.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_batch = tf.reshape(seq_batch, [num_hidden, num_input, 1])\n",
    "labels_batch = tf.reshape(labels_batch, [num_hidden, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 1)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "print seq_batch.get_shape()\n",
    "print labels_batch.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "val, state = tf.nn.dynamic_rnn(cell, seq_batch, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = tf.transpose(val, [1, 0, 2])\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, 1]))\n",
    "bias = tf.Variable(tf.truncated_normal([1]))\n",
    "\n",
    "# Functions definition \n",
    "pred = tf.matmul(last, weight) + bias\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.sqrt(tf.reduce_mean(tf.square(labels_batch - pred)), name='RMSE')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(labels_batch, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-4, started daemon 123145332535296)>,\n",
       " <Thread(Thread-5, started daemon 123145336741888)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568455\n",
      "0.423495\n",
      "0.597345\n",
      "0.481124\n",
      "0.577397\n",
      "0.595392\n",
      "0.582464\n",
      "0.425061\n",
      "0.618704\n",
      "0.589665\n",
      "0.575004\n",
      "0.500331\n",
      "0.440581\n",
      "0.350324\n",
      "0.601807\n",
      "0.627045\n",
      "0.652415\n",
      "0.678657\n",
      "0.627612\n",
      "0.598391\n",
      "0.597733\n",
      "0.649638\n",
      "0.655104\n",
      "0.550912\n",
      "0.435636\n",
      "0.447284\n",
      "0.522478\n",
      "0.566333\n",
      "0.524137\n",
      "0.422922\n",
      "0.499264\n",
      "0.443362\n",
      "0.36989\n",
      "0.495208\n",
      "0.552446\n",
      "0.349727\n",
      "0.471909\n",
      "0.284394\n",
      "0.378921\n",
      "0.338938\n",
      "0.473509\n",
      "0.490843\n",
      "0.460219\n",
      "0.32576\n",
      "0.558713\n",
      "0.548395\n",
      "0.503338\n",
      "0.447485\n",
      "0.452337\n",
      "0.404308\n",
      "0.553269\n",
      "0.41995\n",
      "0.406808\n",
      "0.320705\n",
      "0.537165\n",
      "0.404499\n",
      "0.263595\n",
      "0.406095\n",
      "0.330639\n",
      "0.407099\n",
      "0.406621\n",
      "0.346055\n",
      "0.389151\n",
      "0.337012\n",
      "0.264485\n",
      "0.41394\n",
      "0.427803\n",
      "0.28744\n",
      "0.311523\n",
      "0.295738\n",
      "0.30357\n",
      "0.452755\n",
      "0.328746\n",
      "0.34285\n",
      "0.345744\n",
      "0.219422\n",
      "0.334222\n",
      "0.241489\n",
      "0.290964\n",
      "0.426807\n",
      "0.371165\n",
      "0.448615\n",
      "0.304283\n",
      "0.360129\n",
      "0.333859\n",
      "0.396367\n",
      "0.255257\n",
      "0.327857\n",
      "0.26092\n",
      "0.345118\n",
      "0.365282\n",
      "0.335651\n",
      "0.305021\n",
      "0.373283\n",
      "0.393642\n",
      "0.324472\n",
      "0.272494\n",
      "0.257371\n",
      "0.337004\n",
      "0.367987\n",
      "0.214414\n",
      "0.278464\n",
      "0.302425\n",
      "0.270965\n",
      "0.362138\n",
      "0.234596\n",
      "0.350166\n",
      "0.335237\n",
      "0.275914\n",
      "0.291486\n",
      "0.233908\n",
      "0.260436\n",
      "0.30687\n",
      "0.259736\n",
      "0.322743\n",
      "0.205853\n",
      "0.259751\n",
      "0.24925\n",
      "0.187637\n",
      "0.279579\n",
      "0.177055\n",
      "0.255525\n",
      "0.323322\n",
      "0.222037\n",
      "0.231955\n",
      "0.180561\n",
      "0.261976\n",
      "0.260996\n",
      "0.212482\n",
      "0.281694\n",
      "0.229983\n",
      "0.23695\n",
      "0.217598\n",
      "0.202523\n",
      "0.176192\n",
      "0.263756\n",
      "0.227545\n",
      "0.247612\n",
      "0.168441\n",
      "0.263419\n",
      "0.211022\n",
      "0.260195\n",
      "0.326382\n",
      "0.251202\n",
      "0.260018\n",
      "0.217261\n",
      "0.149442\n",
      "0.186513\n",
      "0.202331\n",
      "0.253577\n",
      "0.178939\n",
      "0.214319\n",
      "0.271761\n",
      "0.252977\n",
      "0.209028\n",
      "0.145298\n",
      "0.245984\n",
      "0.240961\n",
      "0.142104\n",
      "0.230518\n",
      "0.237452\n",
      "0.231919\n",
      "0.233758\n",
      "0.220619\n",
      "0.225346\n",
      "0.257826\n",
      "0.203747\n",
      "0.210202\n",
      "0.193904\n",
      "0.224524\n",
      "0.182031\n",
      "0.279134\n",
      "0.202002\n",
      "0.192808\n",
      "0.17857\n",
      "0.197578\n",
      "0.199227\n",
      "0.240426\n",
      "0.221922\n",
      "0.173907\n",
      "0.18268\n",
      "0.236887\n",
      "0.119571\n",
      "0.168623\n",
      "0.174138\n",
      "0.259041\n",
      "0.228412\n",
      "0.183919\n",
      "0.222663\n",
      "0.268131\n",
      "0.206098\n",
      "0.261034\n",
      "0.22468\n",
      "0.210243\n",
      "0.237138\n",
      "0.266679\n",
      "0.164953\n",
      "0.160023\n",
      "0.196321\n",
      "0.148663\n",
      "0.298493\n",
      "0.249171\n",
      "0.183287\n",
      "0.244018\n",
      "0.219184\n",
      "0.277188\n",
      "0.176594\n",
      "0.203876\n",
      "0.185848\n",
      "0.199456\n",
      "0.181978\n",
      "0.1363\n",
      "0.223289\n",
      "0.219924\n",
      "0.19353\n",
      "0.223269\n",
      "0.203679\n",
      "0.178459\n",
      "0.147627\n",
      "0.232025\n",
      "0.195246\n",
      "0.221718\n",
      "0.12469\n",
      "0.278325\n",
      "0.176094\n",
      "0.211062\n",
      "0.174582\n",
      "0.260611\n",
      "0.180892\n",
      "0.218868\n",
      "0.221402\n",
      "0.153603\n",
      "0.213482\n",
      "0.210585\n",
      "0.161665\n",
      "0.132721\n",
      "0.201093\n",
      "0.175944\n",
      "0.179248\n",
      "0.183885\n",
      "0.196349\n",
      "0.184359\n",
      "0.178803\n",
      "0.203133\n",
      "0.227025\n",
      "0.191255\n",
      "0.205297\n",
      "0.241229\n",
      "0.189706\n",
      "0.195966\n",
      "0.212925\n",
      "0.175181\n",
      "0.158891\n",
      "0.172821\n",
      "0.180367\n",
      "0.141245\n",
      "0.181557\n",
      "0.185968\n",
      "0.167557\n",
      "0.171955\n",
      "0.202257\n",
      "0.17592\n",
      "0.191875\n",
      "0.170193\n",
      "0.145938\n",
      "0.216454\n",
      "0.154022\n",
      "0.177749\n",
      "0.150557\n",
      "0.176631\n",
      "0.201739\n",
      "0.221995\n",
      "0.133817\n",
      "0.170462\n",
      "0.171812\n",
      "0.216108\n",
      "0.186537\n",
      "0.166144\n",
      "0.187442\n",
      "0.219844\n",
      "0.19211\n",
      "0.204408\n",
      "0.198341\n",
      "0.19825\n",
      "0.222288\n",
      "0.131224\n",
      "0.225575\n",
      "0.209141\n",
      "0.223811\n",
      "0.159211\n",
      "0.216547\n",
      "0.196102\n",
      "0.156641\n",
      "0.203793\n",
      "0.201129\n",
      "0.214186\n",
      "0.132993\n",
      "0.177923\n",
      "0.147496\n",
      "0.195624\n",
      "0.157571\n",
      "0.187316\n",
      "0.181363\n",
      "0.164014\n",
      "0.171958\n",
      "0.20321\n",
      "0.187538\n",
      "0.199658\n",
      "0.19173\n",
      "0.150724\n",
      "0.176389\n",
      "0.17876\n",
      "0.164037\n",
      "0.153644\n",
      "0.189259\n",
      "0.207843\n",
      "0.178166\n",
      "0.14819\n",
      "0.195773\n",
      "0.210232\n",
      "0.148422\n",
      "0.205441\n",
      "0.178953\n",
      "0.168886\n",
      "0.207362\n",
      "0.180808\n",
      "0.122757\n",
      "0.15221\n",
      "0.181466\n",
      "0.149543\n",
      "0.186226\n",
      "0.157097\n",
      "0.186297\n",
      "0.1601\n",
      "0.149809\n",
      "0.159429\n",
      "0.184287\n",
      "0.149298\n",
      "0.128866\n",
      "0.178222\n",
      "0.181974\n",
      "0.164276\n",
      "0.188777\n",
      "0.16386\n",
      "0.129139\n",
      "0.118001\n",
      "0.178849\n",
      "0.194133\n",
      "0.142533\n",
      "0.135992\n",
      "0.144733\n",
      "0.169406\n",
      "0.135823\n",
      "0.203741\n",
      "0.126665\n",
      "0.17557\n",
      "0.197573\n",
      "0.176081\n",
      "0.159831\n",
      "0.160976\n",
      "0.153646\n",
      "0.142683\n",
      "0.172303\n",
      "0.171871\n",
      "0.153945\n",
      "0.134227\n",
      "0.136073\n",
      "0.123256\n",
      "0.102091\n",
      "0.189022\n",
      "0.136659\n",
      "0.130247\n",
      "0.146632\n",
      "0.129121\n",
      "0.146502\n",
      "0.149041\n",
      "0.153755\n",
      "0.147242\n",
      "0.123155\n",
      "0.11752\n",
      "0.178171\n",
      "0.131945\n",
      "0.125714\n",
      "0.152406\n",
      "0.183293\n",
      "0.0819886\n",
      "0.149458\n",
      "0.149465\n",
      "0.170798\n",
      "0.103529\n",
      "0.171679\n",
      "0.134522\n",
      "0.163243\n",
      "0.153801\n",
      "0.121058\n",
      "0.101742\n",
      "0.168302\n",
      "0.133956\n",
      "0.185457\n",
      "0.0927081\n",
      "0.167865\n",
      "0.121848\n",
      "0.0953653\n",
      "0.12984\n",
      "0.148735\n",
      "0.122325\n",
      "0.13075\n",
      "0.175382\n",
      "0.12252\n",
      "0.170246\n",
      "0.185642\n",
      "0.111065\n",
      "0.156001\n",
      "0.121007\n",
      "0.129241\n",
      "0.157194\n",
      "0.13689\n",
      "0.111499\n",
      "0.136303\n",
      "0.146346\n",
      "0.127117\n",
      "0.117369\n",
      "0.0774335\n",
      "0.149104\n",
      "0.123587\n",
      "0.106216\n",
      "0.131245\n",
      "0.143516\n",
      "0.123075\n",
      "0.159987\n",
      "0.139999\n",
      "0.150064\n",
      "0.147064\n",
      "0.119678\n",
      "0.106306\n",
      "0.150117\n",
      "0.0853643\n",
      "0.172998\n",
      "0.157703\n",
      "0.0795782\n",
      "0.170691\n",
      "0.116514\n",
      "0.196713\n",
      "0.0815545\n",
      "0.0911982\n",
      "0.13284\n",
      "0.0961575\n",
      "0.138409\n",
      "0.189076\n",
      "0.12495\n",
      "0.140422\n",
      "0.155116\n",
      "0.132897\n",
      "0.079334\n",
      "0.11508\n",
      "0.138014\n",
      "0.0865163\n",
      "0.158455\n",
      "0.0872213\n",
      "0.145522\n",
      "0.105456\n",
      "0.165618\n",
      "0.130253\n",
      "0.094248\n",
      "0.102921\n",
      "0.13755\n",
      "0.111942\n",
      "0.152078\n",
      "0.132795\n",
      "0.107562\n",
      "0.106241\n",
      "0.107212\n",
      "0.118361\n",
      "0.163357\n",
      "0.112175\n",
      "0.137127\n",
      "0.182193\n",
      "0.121204\n",
      "0.16559\n",
      "0.100635\n",
      "0.115183\n",
      "0.0884699\n",
      "0.13487\n",
      "0.11262\n",
      "0.136912\n",
      "0.0956091\n",
      "0.135194\n",
      "0.113869\n",
      "0.139192\n",
      "0.14106\n",
      "0.110713\n",
      "0.118442\n",
      "0.120306\n",
      "0.110417\n",
      "0.123622\n",
      "0.122374\n",
      "0.11261\n",
      "0.0980822\n",
      "0.164046\n",
      "0.132984\n",
      "0.103606\n",
      "0.12269\n",
      "0.148665\n",
      "0.114288\n",
      "0.095517\n",
      "0.140861\n",
      "0.0919565\n",
      "0.119526\n",
      "0.102966\n",
      "0.0720422\n",
      "0.122049\n",
      "0.117315\n",
      "0.135526\n",
      "0.106997\n",
      "0.132855\n",
      "0.101854\n",
      "0.124546\n",
      "0.067904\n",
      "0.128797\n",
      "0.0972938\n",
      "0.178997\n",
      "0.0808686\n",
      "0.0891638\n",
      "0.123915\n",
      "0.118715\n",
      "0.170754\n",
      "0.124292\n",
      "0.115556\n",
      "0.108592\n",
      "0.106671\n",
      "0.100349\n",
      "0.130939\n",
      "0.130998\n",
      "0.144919\n",
      "0.130211\n",
      "0.0792712\n",
      "0.102155\n",
      "0.0949783\n",
      "0.126253\n",
      "0.0736841\n",
      "0.112536\n",
      "0.08001\n",
      "0.105561\n",
      "0.0965536\n",
      "0.0749105\n",
      "0.106237\n",
      "0.10716\n",
      "0.11379\n",
      "0.126397\n",
      "0.123509\n",
      "0.0932853\n",
      "0.105903\n",
      "0.0743126\n",
      "0.0892078\n",
      "0.0995201\n",
      "0.0993499\n",
      "0.116234\n",
      "0.108384\n",
      "0.117643\n",
      "0.124922\n",
      "0.136736\n",
      "0.107895\n",
      "0.100405\n",
      "0.0722797\n",
      "0.0640468\n",
      "0.109296\n",
      "0.101148\n",
      "0.111089\n",
      "0.136576\n",
      "0.0732168\n",
      "0.0840378\n",
      "0.11323\n",
      "0.0884917\n",
      "0.104296\n",
      "0.107068\n",
      "0.0970764\n",
      "0.110421\n",
      "0.108655\n",
      "0.0956805\n",
      "0.0869762\n",
      "0.095936\n",
      "0.0823253\n",
      "0.0744511\n",
      "0.0852481\n",
      "0.116337\n",
      "0.111606\n",
      "0.112819\n",
      "0.117736\n",
      "0.0863642\n",
      "0.0692646\n",
      "0.0947831\n",
      "0.0979211\n",
      "0.101211\n",
      "0.0642634\n",
      "0.084664\n",
      "0.0901018\n",
      "0.0729143\n",
      "0.08227\n",
      "0.0727839\n",
      "0.087473\n",
      "0.099918\n",
      "0.0980321\n",
      "0.0687917\n",
      "0.0761094\n",
      "0.0856261\n",
      "0.0694227\n",
      "0.0917194\n",
      "0.0792782\n",
      "0.107176\n",
      "0.0868043\n",
      "0.078365\n",
      "0.0695446\n",
      "0.0562778\n",
      "0.0721362\n",
      "0.06809\n",
      "0.0816545\n",
      "0.0665426\n",
      "0.0482825\n",
      "0.0853945\n",
      "0.0848108\n",
      "0.0671802\n",
      "0.0796537\n",
      "0.079405\n",
      "0.0832931\n",
      "0.0678066\n",
      "0.0669081\n",
      "0.0874747\n",
      "0.0619479\n",
      "0.0581019\n",
      "0.0805639\n",
      "0.0465899\n",
      "0.081799\n",
      "0.0394403\n",
      "0.0544279\n",
      "0.0736014\n",
      "0.0742074\n",
      "0.0689933\n",
      "0.053425\n",
      "0.0672478\n",
      "0.0851288\n",
      "0.0476503\n",
      "0.0650603\n",
      "0.103001\n",
      "0.0550185\n",
      "0.0812896\n",
      "0.068651\n",
      "0.0648175\n",
      "0.0572428\n",
      "0.0814629\n",
      "0.0682683\n",
      "0.0736743\n",
      "0.0620303\n",
      "0.0420092\n",
      "0.0762952\n",
      "0.0735628\n",
      "0.0479526\n",
      "0.0188318\n",
      "0.0707832\n",
      "0.0524672\n",
      "0.0562223\n",
      "0.0577645\n",
      "0.0692261\n",
      "0.0748517\n",
      "0.0653172\n",
      "0.047831\n",
      "0.0795242\n",
      "0.0475682\n",
      "0.058205\n",
      "0.066488\n",
      "0.0685212\n",
      "0.0559972\n",
      "0.057683\n",
      "0.0622275\n",
      "0.0643845\n",
      "0.0595896\n",
      "0.069845\n",
      "0.0410249\n",
      "0.0429158\n",
      "0.0613827\n",
      "0.0511942\n",
      "0.0467562\n",
      "0.0709674\n",
      "0.0585849\n",
      "0.0558248\n",
      "0.0477089\n",
      "0.0702848\n",
      "0.0584708\n",
      "0.054653\n",
      "0.0676207\n",
      "0.0639039\n",
      "0.0681378\n",
      "0.0330786\n",
      "0.0494777\n",
      "0.0502005\n",
      "0.0664266\n",
      "0.0656567\n",
      "0.0637304\n",
      "0.0513699\n",
      "0.0496985\n",
      "0.0523147\n",
      "0.0480607\n",
      "0.0664629\n",
      "0.0519331\n",
      "0.0588764\n",
      "0.0618813\n",
      "0.0250526\n",
      "0.0585346\n",
      "0.0596919\n",
      "0.0541429\n",
      "0.0617486\n",
      "0.0474067\n",
      "0.0515027\n",
      "0.0568218\n",
      "0.053448\n",
      "0.0495411\n",
      "0.0525868\n",
      "0.0555926\n",
      "0.0405027\n",
      "0.0585665\n",
      "0.0469057\n",
      "0.0554021\n",
      "0.0522779\n",
      "0.0549571\n",
      "0.0463687\n",
      "0.0718993\n",
      "0.0580102\n",
      "0.0530449\n",
      "0.0472217\n",
      "0.0500411\n",
      "0.0434892\n",
      "0.0673811\n",
      "0.0475426\n",
      "0.0569188\n",
      "0.0408195\n",
      "0.0523715\n",
      "0.0344804\n",
      "0.0519129\n",
      "0.0543717\n",
      "0.05328\n",
      "0.0515815\n",
      "0.0629253\n",
      "0.052463\n",
      "0.0375734\n",
      "0.0475299\n",
      "0.0411595\n",
      "0.041384\n",
      "0.0497294\n",
      "0.0478931\n",
      "0.0502696\n",
      "0.053043\n",
      "0.0388369\n",
      "0.0684756\n",
      "0.0805131\n",
      "0.0532828\n",
      "0.0524881\n",
      "0.0451465\n",
      "0.0470712\n",
      "0.0382635\n",
      "0.026417\n",
      "0.0320181\n",
      "0.0296797\n",
      "0.0355958\n",
      "0.0326794\n",
      "0.0358622\n",
      "0.0395717\n",
      "0.0344828\n",
      "0.0384369\n",
      "0.0382342\n",
      "0.0390079\n",
      "0.0474777\n",
      "0.0477651\n",
      "0.0410182\n",
      "0.0246522\n",
      "0.0196556\n",
      "0.0296739\n",
      "0.0514214\n",
      "0.0507615\n",
      "0.0408828\n",
      "0.0593289\n",
      "0.0541618\n",
      "0.0382412\n",
      "0.0409987\n",
      "0.0399065\n",
      "0.0464754\n",
      "0.0374018\n",
      "0.0428169\n",
      "0.0433571\n",
      "0.0367586\n",
      "0.0458168\n",
      "0.0471201\n",
      "0.0393696\n",
      "0.0407868\n",
      "0.0293872\n",
      "0.0367979\n",
      "0.0378224\n",
      "0.0416523\n",
      "0.0236114\n",
      "0.0158949\n",
      "0.0494057\n",
      "0.0315938\n",
      "0.043816\n",
      "0.0507802\n",
      "0.0263359\n",
      "0.0382789\n",
      "0.0125502\n",
      "0.0302135\n",
      "0.0453531\n",
      "0.0127683\n",
      "0.036267\n",
      "0.0257377\n",
      "0.0353727\n",
      "0.0512825\n",
      "0.0351486\n",
      "0.0259842\n",
      "0.0345064\n",
      "0.0424924\n",
      "0.0527711\n",
      "0.0341513\n",
      "0.0417\n",
      "0.0311058\n",
      "0.0309075\n",
      "0.0341053\n",
      "0.0242878\n",
      "0.0402028\n",
      "0.0327229\n",
      "0.040768\n",
      "0.0359796\n",
      "0.0319382\n",
      "0.0306342\n",
      "0.0349951\n",
      "0.029095\n",
      "0.0419962\n",
      "0.0333697\n",
      "0.0641013\n",
      "0.0310821\n",
      "0.0280549\n",
      "0.0190842\n",
      "0.0271742\n",
      "0.0233641\n",
      "0.0227417\n",
      "0.0140191\n",
      "0.0277943\n",
      "0.0422832\n",
      "0.0436751\n",
      "0.019618\n",
      "0.0251305\n",
      "0.0219504\n",
      "0.0264372\n",
      "0.0124873\n",
      "0.0256228\n",
      "0.0426368\n",
      "0.0480005\n",
      "0.0390432\n",
      "0.0314962\n",
      "0.0355728\n",
      "0.0238721\n",
      "0.0228246\n",
      "0.0380868\n",
      "0.0498843\n",
      "0.0399247\n",
      "0.0274117\n",
      "0.0261863\n",
      "0.0439173\n",
      "0.0213283\n",
      "0.019538\n",
      "0.0320781\n",
      "0.0271467\n",
      "0.0177994\n",
      "0.0364567\n",
      "0.0291348\n",
      "0.0426093\n",
      "0.0296855\n",
      "0.0398471\n",
      "0.0225355\n",
      "0.0236995\n",
      "0.0229588\n",
      "0.0242126\n",
      "0.0186716\n",
      "0.0368639\n",
      "0.0224189\n",
      "0.0265473\n",
      "0.0245377\n",
      "0.0206274\n",
      "0.0301217\n",
      "0.00481737\n",
      "0.0256811\n",
      "0.0366813\n",
      "0.0257463\n",
      "0.0291185\n",
      "0.0274373\n",
      "0.0242594\n",
      "0.0196654\n",
      "0.0238278\n",
      "0.0216399\n",
      "0.0172218\n",
      "0.0158861\n",
      "0.0204293\n",
      "0.0419942\n",
      "0.034419\n",
      "0.0182733\n",
      "0.031803\n",
      "0.0201818\n",
      "0.0224996\n",
      "0.022066\n",
      "0.00984299\n",
      "0.0185764\n",
      "0.0143346\n",
      "0.0269081\n",
      "0.0395395\n",
      "0.0445526\n",
      "0.016477\n",
      "0.0340985\n",
      "0.0215064\n",
      "0.0100365\n",
      "0.0139245\n",
      "0.0373421\n",
      "0.0171914\n",
      "0.0323972\n",
      "0.0247522\n",
      "0.0219442\n",
      "0.0257288\n",
      "0.0173598\n",
      "0.0311896\n",
      "0.0232603\n",
      "0.0238833\n",
      "0.0173825\n",
      "0.0115558\n",
      "0.0211669\n",
      "0.031998\n",
      "0.0190566\n",
      "0.0194873\n",
      "0.0285962\n",
      "0.0210466\n",
      "0.029117\n",
      "0.031064\n",
      "0.0253329\n",
      "0.0219988\n",
      "0.0158176\n",
      "0.0130487\n",
      "0.0303138\n",
      "0.0300452\n",
      "0.0130177\n",
      "0.0209605\n",
      "0.0283284\n",
      "0.0145905\n",
      "0.0279594\n",
      "0.0143816\n",
      "0.0174861\n",
      "0.0123104\n",
      "0.00938896\n",
      "0.0159406\n",
      "0.0288985\n",
      "0.0202739\n",
      "0.0164386\n",
      "0.0242172\n",
      "0.0222046\n",
      "0.0218647\n",
      "0.0168833\n",
      "0.0205853\n",
      "0.0134223\n",
      "0.0286881\n",
      "0.0139094\n",
      "0.0177078\n",
      "0.01998\n",
      "0.0224019\n",
      "0.0206836\n",
      "0.0213716\n",
      "0.0183537\n",
      "0.0153856\n",
      "0.0182819\n",
      "0.0176264\n",
      "0.020175\n",
      "0.0196945\n",
      "0.0222317\n",
      "0.00809828\n",
      "0.018983\n",
      "0.0144294\n",
      "0.0106565\n",
      "0.00825242\n",
      "0.0219406\n",
      "0.027818\n",
      "0.0135307\n",
      "0.0152974\n",
      "0.0191361\n",
      "0.00815837\n",
      "0.0117534\n",
      "0.0108644\n",
      "0.0181442\n",
      "0.0200013\n",
      "0.01534\n",
      "0.0185249\n",
      "0.0202139\n",
      "0.0124157\n",
      "0.0188809\n",
      "0.0092735\n",
      "0.0195694\n",
      "0.0167597\n",
      "0.0237193\n",
      "0.024105\n",
      "0.0169975\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "  # pass it in through the feed_dict\n",
    "  _, loss_val = sess.run([optimizer, cost])\n",
    "  print loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.998035664431685,\n",
       " 1.99215037495519,\n",
       " 1.9823672529374121,\n",
       " 1.9687247330474484,\n",
       " 1.951276412259422,\n",
       " 1.9300908392875948,\n",
       " 1.9052512452810149,\n",
       " 1.876855216835701,\n",
       " 1.8450143126090013,\n",
       " 1.8098536250423152]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7715112889140305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.79789829]\n",
      " [ 1.76347733]\n",
      " [ 1.72545743]\n",
      " [ 1.68392062]\n",
      " [ 1.63899827]]\n"
     ]
    }
   ],
   "source": [
    "# Train predicted\n",
    "test = np.array(input_data[:5])\n",
    "test = test.reshape(5, 10, 1)\n",
    "pred = sess.run(pred ,{seq_batch: test})\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8098536250423152,\n",
       " 1.7715112889140305,\n",
       " 1.7301379386534053,\n",
       " 1.6858961165474338,\n",
       " 1.6389596341656558]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
